{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d40826d5-9d2c-485a-8ff4-5ff473ea6172",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# etl/api_extracao.ipynb\n",
    "\n",
    "# Configurações\n",
    "site_url = \"https://<tenant>.sharepoint.com/sites/<site>\"\n",
    "username = dbutils.secrets.get('scope-sharepoint', 'sp_username')\n",
    "password = dbutils.secrets.get('scope-sharepoint', 'sp_password')\n",
    "file_url = \"/sites/<site>/Shared Documents/crm_data.xlsx\"\n",
    "local_path_crm = \"/dbfs/team/Volumes/temp/crm_data.xlsx\"\n",
    "\n",
    "host = \"<sftp_host>\"\n",
    "port = 22\n",
    "username_sftp = dbutils.secrets.get('scope-marketing', 'sftp_username')\n",
    "password_sftp = dbutils.secrets.get('scope-marketing', 'sftp_password')\n",
    "remote_path   = \"/path/to/marketing_data.csv\"\n",
    "local_path_marketing = \"/dbfs/team/Volumes/temp/marketing_data.csv\"\n",
    "\n",
    "# Extração dos dados do CRM\n",
    "ctx = connect_to_sharepoint(site_url, username, password)\n",
    "download_file_from_sharepoint(ctx, file_url, local_path_crm)\n",
    "crm_data = pd.read_excel(local_path_crm) #transforma em Pandas Dataframe\n",
    "crm_spark_df = spark.createDataFrame(crm_data) #converte para Spark Dataframe\n",
    "\n",
    "# Extração dos dados do Marketing Cloud\n",
    "sftp = connect_to_sftp(host, port, username_sftp, password_sftp)\n",
    "download_file_from_sftp(sftp, remote_path, local_path_marketing)\n",
    "marketing_data_df  = spark.read.options(header=True, sep:';').csv(local_path_marketing)\n",
    "\n",
    "# Extração dos dados dos demais canais\n",
    "\n",
    "recomendacao_data = spark.read.parquet(\"s3://bucket/recomendacao_data\")\n",
    "restritos_data \t  = spark.read.json(\"s3://bucket/restritos_data\")\n",
    "ofertas_data \t  = spark.read.format(\"delta\").table(\"catalog.database.ofertas_data\") \n",
    "fraude_data \t  = spark.read.format(\"delta\").table(\"catalog.database.fraude_data\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "etl_api_extracao",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
